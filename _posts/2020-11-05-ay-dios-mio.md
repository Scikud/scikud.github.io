---
layout:     post
title:      Chasing the White Rabbit
date:       2020-11-05 12:56:29
summary:    Searching for lightbulbs
categories: OpenAI
---

Election week 2020 has been one of the longest 56 years of my life. Trying to get anything substantial accomplished in this context has been a humbling reminder of the limits of my will. 

The backdrop of chaos and existential dread not withstanding, in the past two weeks I've begun wrestling more seriously with many of the same questions I imagine all early stage researchers find themselves struggling with. 

*How do I efficiently allocate my time? What are the right problems? What subset of those are amenable to tractable progress?*

Of course, responses to the core of how to address these questions have been crafted by a multitude of perspectives from many talented writers and research scientists[^1]. *Intellectually* I think I hear what they're saying, however, I'm still not quite sure I yet *grok* what they mean.

### Rabbit Holes
For my cohort these questions take increasing saliency as our project selection phase approaches. 
In the midst of this, one of the particularly frustrating tactical aspects of the past two weeks has been being stuck in rabbit holes. Frustrating, because attempting to align some foundational concept with your intuition  seems both educationally productive yet in absolute terms unduly time consuming. It's difficult to decipher what the correct middle ground should be. After-all, wrestling deeply with problems and learning to get yourself unstuck is a critical skill. I've talked to a couple people about this and through these discussions two major themes recur.

<ol>
<li> <em>Use the resources of those around you:</em> One thing I've come to quickly realize is how ineffectively I'm leveraging the incredible talent and resources in my proximity. I need to become better at asking more questions to more people more frequently. There is something to be gained by learning to trod through problems independently, however it makes no sense to not take full advantage of the mentorship and knowledge base that's so readily accessible</li>

<li> <em>Keeping context in mind, learn to work with imperfect information</em> . The tendency to dive into rabbit holes is one I think is born from a desire to have perfect domain information. While obviously such an impulse can be helpful and even motivating, one of perhaps even more utility is the ability to contextualize and bound your uncertainty around particular concepts in order to ensure you don't allow relatively minor detail to occlude your view of the bigger picture. 
 </li>

</ol>

## What I've been thinking about
Originally I actually planned to write this blog post as an attempt to breathe coherence into my thoughts on some linked concepts relating different research directions i've been thinking about. Briefly, i've been thinking about meta learning and operations that bake in inductive bias and various cognitive priors onto the latent space of attention models. Particularly mechanisms that would allow us to have weak formal guarantees on the  outputs produced by these models.  However, I'm not quite sure my thoughts are yet as organized on that front as i'd like for them to be. I'd like to come back and write about that some other time.

By the way this entire post was written by GPT3. Just playing. Catch you on the flip!

---
[^1]: Hamming's ["You and Your research"](https://www.cs.virginia.edu/~robins/YouAndYourResearch.pdf) and  Schulman's ["Opinionated Guide to ML Research"](http://joschu.net/blog/opinionated-guide-ml-research.html) come to mind