<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>OpenAIs Scholars Initial Thoughts &#8211; ForceMultiplied</title>
    <link rel="dns-prefetch" href="//fonts.googleapis.com">
    <link rel="dns-prefetch" href="//fonts.gstatic.com">
    <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com">
    <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="New blog who dis?">
    <link rel="manifest" type="application/manifest+json; charset=utf-8" href="/manifest.json" />
    <meta name="robots" content="all">
    <meta name="author" content="Kudzo Ahegbebu">
    
    <meta name="keywords" content="OpenAI, pixylls, jeykll">
    <link rel="canonical" href="http://localhost:4000/openai/pixylls/jeykll/2020/10/22/new-blog-who-dis/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for ForceMultiplied" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?202101191627" type="text/css">

    <!-- Fonts -->
    
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
    

    <!-- MathJax -->
    

    <!-- Verifications -->
    
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="OpenAIs Scholars Initial Thoughts">
    <meta property="og:description" content=".">
    <meta property="og:url" content="http://localhost:4000/openai/pixylls/jeykll/2020/10/22/new-blog-who-dis/">
    <meta property="og:site_name" content="ForceMultiplied">
    

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
    <meta name="twitter:title" content="OpenAIs Scholars Initial Thoughts" />
    <meta name="twitter:description" content="New blog who dis?" />
    <meta name="twitter:url" content="http://localhost:4000/openai/pixylls/jeykll/2020/10/22/new-blog-who-dis/" />
    

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="shortcut icon" href="/favicon.ico">

    
    <script type="text/javascript">
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
       (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
       })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       ga('create', 'UA-110849882-1', 'auto');
       ga('send', 'pageview');
    </script>
    
</head>

<body class="site animated fade-in-down">
  
	

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="/" class="site-title">ForceMultiplied</a>
      <nav class="site-nav">
        



    
    
    
    
        <a class="nav-link" href="/404.html">404</a>
    

    

    
    
    
    
        <a class="nav-link" href="/contact/">Say Hello</a>
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    

    
    
    
    

    


      </nav>
      <div class="clearfix"></div>
      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
  type="text/javascript"></script>



<div class="post-header mb2">
  <h1>OpenAIs Scholars Initial Thoughts</h1>
  <span class="post-meta">Oct 22, 2020</span><br>
  
  <span class="post-meta small">
    
    2 minute read
    
  </span>
</div>

<article class="post-content">
  <p>I’m starting a new blog<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>  to mark the beginning of my time as part of the OpenAI scholar’s program</p>

<h2 id="things-im-excited-about">Things I’m excited about</h2>
<p>I’m deeply excited and humbled to work with such an incredible and deeply talented pool of individuals, both within my cohort and within OpenAI in general. The first week has been such a whirlwind of excitement. I’ve spent much of it shoring up my foundations in machine learning theory and application as well tyring to find my bearings in the wide sea of research interests.</p>

<p>I joined this program because of my belief that well aligned machine intelligence can act as an incredible force multiplier for a wide range of human endeavors. I’m most excited by the incredible generality of deep learning; the remarkable ability to abstract and  apply the same set of algorithms to a wide range of seemingly disparate problems. This paradigm excites me because it  reimagines computers and computation as being more than numerical automata but as robust tools capable of ingesting and producing rich inputs and outputs allowing us to augment our own problem solving capacity and by extension amplify ingenuity and improve the human condition. Honestly, what could be more exciting or compelling as a research interest?</p>

<h2 id="ramblings">Ramblings</h2>
<p>One thing I’ve personally found useful is keep running track of ideas that emerge during the course of self study. I’ve found this idea tracking helpful in the meta-sense; in that, over time it helps me see emerging trends in my train of thought. I’m really not sure how useful these stream of consciousness type expositions will be for others, but nevertheless here are some of my thoughts from this week:</p>

<ol>
  <li>
    <p>Training a neural network produces a model that we can think of as some object whose weights and biases provide discrete estimates of the high dimensional manifold our training data lies on. Along this train of thought, can we  think of the hyperparameters of two different networks trained on the same data as two different samples of the same underlying ‘true’ manifold? What then is the relationship (if any) between the weights of these two models? Is it possible to be clever and somehow combine these two manifold samplings to get a better estimate of the true manifold ala something loosely analogous to <a href="https://francisbach.com/richardson-extrapolation/">Richardson Extrapolation</a> /Bayesian updating ?</p>
  </li>
  <li>
    <p>When training neural networks we typically include as part of the loss function, a regularization term. The idea behind this is that penalizing large model weights we can prevent the co-adaptation of network weights and limit the networks ability to learn local noise in the underlying training data thus leading to better generalization.  The regularization terms i’ve seen thus far are fairy straightforward l1 or l2 norms on the network weights. I’m curious to explore the effectiveness of regularizing with more sophisticated techniques. Like regularizing with the goal to minimize entropy or something along that vein.</p>
  </li>
</ol>

<p>That’s it for now. Catch you all later!</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>For the literally two people who read the single post in the old blog, I’ve migrated that post as well :) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

</article>










      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      Theme available on <a href="https://github.com/johnotander/pixyll">GitHub</a>.
    </small>
  </div>
</footer>

<script type="text/javascript">
  if ("serviceWorker" in navigator) {
    navigator.serviceWorker.register("/sw.js")
  }
</script>
</body>
</html>
